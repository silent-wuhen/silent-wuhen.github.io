<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Hadoop大数据处理 | My Blog</title><meta name="author" content="HQH"><meta name="copyright" content="HQH"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="前言视频推荐：黑马程序员 为了让我快速搭建Hadoop集群，因为学习的过程中总会有配置出错的时候，再加上Hadoop集群搭建一次需要消耗的时间实在是太长了，所以写了这个笔记。当然，我也省略了很多操作，比如打开vim之后，输入i开始编辑，按esc退出编辑模式，:wq保存退出。所以需要熟悉一点点Linux命令。 温馨提示：建议每次搭建好了一个集群之后，就拍摄一次快照（虽然一个快照3个G大小左右）。 第">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop大数据处理">
<meta property="og:url" content="http://example.com/2023/11/18/3.%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B1%BB/1.Hadoop%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%EF%BC%88%E6%9C%AA%E5%AE%8C%E7%BB%93%EF%BC%89/index.html">
<meta property="og:site_name" content="My Blog">
<meta property="og:description" content="前言视频推荐：黑马程序员 为了让我快速搭建Hadoop集群，因为学习的过程中总会有配置出错的时候，再加上Hadoop集群搭建一次需要消耗的时间实在是太长了，所以写了这个笔记。当然，我也省略了很多操作，比如打开vim之后，输入i开始编辑，按esc退出编辑模式，:wq保存退出。所以需要熟悉一点点Linux命令。 温馨提示：建议每次搭建好了一个集群之后，就拍摄一次快照（虽然一个快照3个G大小左右）。 第">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/%E5%9B%BE%E7%89%87/015.jpg">
<meta property="article:published_time" content="2023-11-18T15:16:12.000Z">
<meta property="article:modified_time" content="2024-04-05T12:57:22.727Z">
<meta property="article:author" content="HQH">
<meta property="article:tag" content="大数据">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/%E5%9B%BE%E7%89%87/015.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2023/11/18/3.%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B1%BB/1.Hadoop%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%EF%BC%88%E6%9C%AA%E5%AE%8C%E7%BB%93%EF%BC%89/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体中文","cht_to_chs":"你已切换为简体中文","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Hadoop大数据处理',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-04-05 20:57:22'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://www.fomal.cc/static/css/runtime.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/touxiang.JPG" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">12</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/%E5%9B%BE%E7%89%87/015.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="My Blog"></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><!-- span=' '+_p('search.title')--></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Hadoop大数据处理</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-11-18T15:16:12.000Z" title="发表于 2023-11-18 23:16:12">2023-11-18</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-04-05T12:57:22.727Z" title="更新于 2024-04-05 20:57:22">2024-04-05</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>21分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Hadoop大数据处理"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>视频推荐：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1WY4y197g7/?spm_id_from=333.337.search-card.all.click&vd_source=bd0b10b1a89eeb70aae017bf4b5233c3">黑马程序员</a></p>
<p>为了让我快速搭建Hadoop集群，因为学习的过程中总会有配置出错的时候，再加上Hadoop集群搭建一次需要消耗的时间实在是太长了，所以写了这个笔记。当然，我也省略了很多操作，比如打开vim之后，输入i开始编辑，按esc退出编辑模式，:wq保存退出。所以需要熟悉一点点Linux命令。</p>
<p>温馨提示：建议每次搭建好了一个集群之后，就拍摄一次快照（虽然一个快照3个G大小左右）。</p>
<h1 id="第一章-搭建Hadoop集群"><a href="#第一章-搭建Hadoop集群" class="headerlink" title="第一章 搭建Hadoop集群"></a>第一章 搭建Hadoop集群</h1><h2 id="搭建准备"><a href="#搭建准备" class="headerlink" title="搭建准备"></a>搭建准备</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.下载vmware</span><br><span class="line">2.下载centos镜像</span><br><span class="line">3.配置vmware虚拟机的网络设置</span><br><span class="line">4.安装好centos，命名为hadoop01</span><br><span class="line">5.打开终端，输入：</span><br><span class="line">ping www.baidu.com</span><br><span class="line">6.有数据包传输，表明网络没有问题，输入：ctrl + c来终止</span><br></pre></td></tr></table></figure>

<p>以上配置如果不会可以看视频：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Kf4y1z7Nw?p=1&vd_source=bd0b10b1a89eeb70aae017bf4b5233c3">Hadoop安装</a></p>
<h2 id="正式搭建"><a href="#正式搭建" class="headerlink" title="正式搭建"></a>正式搭建</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">以下正式开始，注意root登录：</span><br><span class="line"><span class="number">1.</span>创建/export目录，在export目录下创建data，servers,software三个目录：</span><br><span class="line">mkdir -p /export/data /export/servers /export/software</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span>克隆两个虚拟机并命名为hadoop02，hadoop03</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span>配置主机名，修改后重新打开终端可以查看：(<span class="number">3</span>个都要操作)</span><br><span class="line">hostnamectl <span class="built_in">set</span>-hostname 主机名</span><br><span class="line"></span><br><span class="line"><span class="number">4.</span>IP映射配置（<span class="number">3</span>个，IP地址参考自己的）</span><br><span class="line">vim /etc/hosts</span><br><span class="line"><span class="number">192.168</span><span class="number">.121</span><span class="number">.134</span> hadoop01</span><br><span class="line"><span class="number">192.168</span><span class="number">.121</span><span class="number">.135</span> hadoop02</span><br><span class="line"><span class="number">192.168</span><span class="number">.121</span><span class="number">.136</span> hadoop03</span><br><span class="line"></span><br><span class="line"><span class="number">5.</span>设置静态IP(最后ens33可能不同，输入en然后TAB	键补齐),<span class="number">3</span>个修改：</span><br><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-ens33</span><br><span class="line">修改（没有的需要自己打）：</span><br><span class="line">BOOTPROTO=<span class="string">&quot;static&quot;</span></span><br><span class="line">ONBOOT=<span class="string">&quot;yes&quot;</span></span><br><span class="line">IPADDR=<span class="number">192.168</span><span class="number">.121</span><span class="number">.134</span></span><br><span class="line">GATEWAY=<span class="number">192.168</span><span class="number">.121</span><span class="number">.2</span></span><br><span class="line">NETMASK=<span class="number">255.255</span><span class="number">.255</span><span class="number">.0</span></span><br><span class="line">DNS1=<span class="number">8.8</span><span class="number">.8</span><span class="number">.8</span></span><br><span class="line"></span><br><span class="line"><span class="number">6.</span>可选，修改时区并配置自动时间同步（<span class="number">3</span>个）：</span><br><span class="line">安装ntp软件</span><br><span class="line">yum install -y ntp</span><br><span class="line">更新时区</span><br><span class="line">rm -f /etc/localtime;sudo ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br><span class="line">同步时间</span><br><span class="line">ntpdate -u ntp.aliyun.com</span><br><span class="line">开启ntp服务并设置开机自启</span><br><span class="line">systemctl start ntpd</span><br><span class="line">systemctl enable ntpd</span><br><span class="line"></span><br><span class="line"><span class="number">7.</span>重启（<span class="number">3</span>个），输入：</span><br><span class="line">reboot</span><br><span class="line">ping www.baidu.com</span><br><span class="line">有数据包传输，表明网络没有问题，输入：ctrl + c来终止</span><br><span class="line"></span><br><span class="line"><span class="number">8.</span>SSH免密登录，输入：</span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line">连续<span class="number">4</span>次回车</span><br><span class="line">cd ~/.ssh</span><br><span class="line">ssh-copy-<span class="built_in">id</span> hadoop01</span><br><span class="line">ssh-copy-<span class="built_in">id</span> hadoop02</span><br><span class="line">ssh-copy-<span class="built_in">id</span> hadoop03</span><br><span class="line">ssh hadoop01</span><br><span class="line">输入密码</span><br><span class="line">ssh hadoop02</span><br><span class="line">输入密码</span><br><span class="line">ssh hadoop03</span><br><span class="line">输入密码</span><br><span class="line"></span><br><span class="line"><span class="number">9.J</span>DK和Hadoop安装,注意以下版本号请根据实际版本号：</span><br><span class="line">使用xFTP上传JDK和Hadoop安装包到/export/software/</span><br><span class="line">cd /export/software/</span><br><span class="line">tar -zxvf jdk-8u241-linux-x64.tar.gz -C /export/servers/</span><br><span class="line">tar -zxvf hadoop-<span class="number">2.10</span><span class="number">.0</span>.tar.gz -C /export/servers/</span><br><span class="line">cd /export/servers/</span><br><span class="line">mv jdk-8u241-linux-x64 jdk-<span class="number">1.8</span><span class="number">.0</span></span><br><span class="line">mv hadoop-<span class="number">2.10</span><span class="number">.0</span> hadoop-<span class="number">2.10</span><span class="number">.0</span> (这里解压后文件名一样，可以不修改)</span><br><span class="line"></span><br><span class="line"><span class="number">9.</span>配置环境变量：</span><br><span class="line">vim /etc/profile</span><br><span class="line">在文件最底部输入：</span><br><span class="line">export JAVA_HOME=/export/servers/jdk-<span class="number">1.8</span><span class="number">.0</span></span><br><span class="line">export PATH=$PATH:$JAVA_HOME/<span class="built_in">bin</span></span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"></span><br><span class="line">export HADOOP_HOME=/export/servers/hadoop-<span class="number">2.10</span><span class="number">.0</span></span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/<span class="built_in">bin</span>:$HADOOP_HOME/sbin</span><br><span class="line"></span><br><span class="line">退出后：</span><br><span class="line">source /etc/profile</span><br><span class="line">java -version</span><br><span class="line">hadoop version</span><br></pre></td></tr></table></figure>

<p>到此没有出现错误的话，那么恭喜，可以接着往下一步进行了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line">接下来对主节点hadoop01进行配置：</span><br><span class="line">（1）</span><br><span class="line">cd /export/servers/hadoop-2.10.0/etc/hadoop</span><br><span class="line">vim hadoop-env.sh </span><br><span class="line">找到export JAVA_HOME，修改为：</span><br><span class="line">export JAVA_HOME=/export/servers/jdk-1.8.0</span><br><span class="line"></span><br><span class="line">（2）</span><br><span class="line">vim core-site.xml </span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;hdfs://hadoop01:9000&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;/export/servers/hadoop-2.10.0/tmp&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">（3）</span><br><span class="line">vim hdfs-site.xml </span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;3&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;hadoop02:5009&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line">（4）</span><br><span class="line">cp mapred-site.xml.template mapred-site.xml</span><br><span class="line">vim mapred-site.xml</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;mapreduce.framework&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line">（5）</span><br><span class="line">vim yarn-site.xml</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- Site specific YARN configuration properties --&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;hadoop01&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line">（6）</span><br><span class="line"> vim slaves </span><br><span class="line"> </span><br><span class="line">hadoop01</span><br><span class="line">hadoop02</span><br><span class="line">hadoop03</span><br><span class="line"></span><br><span class="line">（7）</span><br><span class="line">scp /etc/profile hadoop02:/etc/profile</span><br><span class="line">scp /etc/profile hadoop03:/etc/profile</span><br><span class="line">scp -r /export/ hadoop02:/</span><br><span class="line">scp -r /export/ hadoop03:/</span><br><span class="line"></span><br><span class="line">然后3个需要输入：</span><br><span class="line">source /etc/profile</span><br><span class="line"></span><br><span class="line">需要对主节点hadoop01操作</span><br><span class="line">（8）必须格式化处理一次</span><br><span class="line">cd /export/servers/hadoop-2.10.0</span><br><span class="line">ls -l</span><br><span class="line">如果有tmp目录</span><br><span class="line">需要输入：rm -rf /export/servers/hadoop-2.10.0/tmp/</span><br><span class="line">格式化：</span><br><span class="line">hadoop namenode -format</span><br></pre></td></tr></table></figure>

<p>如果到此没有出错，那么需要进行一下最最最重要的一步：</p>
<p><strong>拍摄快照</strong>，<strong>拍摄快照</strong>，<strong>拍摄快照</strong></p>
<p>重要的事情说三遍。</p>
<h2 id="Hadoop集群测试"><a href="#Hadoop集群测试" class="headerlink" title="Hadoop集群测试"></a>Hadoop集群测试</h2><p><strong>注：每次开机需要启动一次服务</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">（1）启动服务</span><br><span class="line">start-dfs.sh</span><br><span class="line">start-yarn.sh</span><br><span class="line">注：start换成stop停止服务</span><br><span class="line"></span><br><span class="line">（2）查看服务</span><br><span class="line">jps</span><br><span class="line"></span><br><span class="line">（3）通过UI查看Hadoop运行状态</span><br><span class="line">在浏览器网址栏输入：</span><br><span class="line">HDFS的UI端口：</span><br><span class="line">hadoop01:50070</span><br><span class="line">YARN的UI端口：</span><br><span class="line">hadoop01:8088</span><br></pre></td></tr></table></figure>



<h2 id="Hadoop集群初体验"><a href="#Hadoop集群初体验" class="headerlink" title="Hadoop集群初体验"></a>Hadoop集群初体验</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">（1）在/export/data目录下，输入：</span><br><span class="line">cd /export/data</span><br><span class="line">vim word.txt</span><br><span class="line">编写内容：</span><br><span class="line">hello world</span><br><span class="line">hello computer</span><br><span class="line">hello hadoop</span><br><span class="line"></span><br><span class="line">（2）在HDFS上创建/wordcount/input,并上传word.txt:</span><br><span class="line">hadoop fs -mkdir -p /wordcount/input</span><br><span class="line">hadoop fs -put /export/data/word.txt /wordcount/input</span><br><span class="line"></span><br><span class="line">（3）HDFS的UI端口查看：</span><br><span class="line">hadoop01:50070</span><br><span class="line"></span><br><span class="line">（4）查看MapReduce实例程序：</span><br><span class="line">cd /export/servers/hadoop-2.10.0/share/hadoop/mapreduce</span><br><span class="line">ls -l</span><br><span class="line">hadoop jar hadoop-mapreduce-examples-2.10.0.jar wordcount /wordcount/input /wordcount/output</span><br><span class="line"></span><br><span class="line">（5）HDFS的UI端口查看结果：</span><br><span class="line">hadoop01:50070</span><br></pre></td></tr></table></figure>



<h1 id="第二章-初识Hadoop"><a href="#第二章-初识Hadoop" class="headerlink" title="第二章 初识Hadoop"></a>第二章 初识Hadoop</h1><ol>
<li><p>什么是大数据？</p>
<p>大数据是数字化时代、信息化时代的基础（技术）支撑，以数据为生活赋能。</p>
</li>
<li><p>大数据的4个主要特征（4v）：</p>
<p>大量（volume）</p>
<p>多样（variety）：结构化数据，非结构化数据，半结构化数据</p>
<p>高速（velocity）：</p>
<p>价值（value）：价值密度的高低和数据总量的大小成反比。</p>
</li>
<li><p>大数据的应用场景：医疗行业的应用，金融行业的应用，零售业的应用</p>
</li>
<li><p>Hadoop的优势：</p>
<p>扩容能力强</p>
<p>成本低</p>
<p>高效率</p>
<p>可靠性</p>
<p>高容错率</p>
</li>
<li><p>Hadoop的生态体系：</p>
<ol>
<li><p>分布式存储系统（HDFS）：</p>
<p>Hadoop分布式文件系统的简称</p>
</li>
<li><p>MapReduce分布式计算框架：</p>
<p>是一种计算模型，用于大规模数据集的并行计算</p>
</li>
<li><p>YARN资源管理平台：</p>
<p>Hadoop2.0中的资源管理器，为上层的应用提供统一的资源管理和调度</p>
</li>
<li><p>Sqoop数据迁移工具：</p>
<p>用于Hadoop和传统数据库间进行数据的转换。</p>
</li>
<li><p>Mahout数据挖掘算法库：</p>
<p>方便快捷地创建智能应用程序</p>
</li>
<li><p>HBase分布式数据库：</p>
<p>针对结构化数据的可伸缩、高可靠、高性能、分布式和面向列的动态模型数据库</p>
</li>
<li><p>Zookeeper分布式协调服务：</p>
<p>分布式应用程序协调服务</p>
</li>
<li><p>Hive基于Hadoop的数据仓库：</p>
<p>可以将结构化的数据文件映射为一张数据表</p>
</li>
<li><p>Flume日志收集工具：</p>
<p>是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统。支持在日志系统中定制各类数据发送方用于收集数据。</p>
</li>
</ol>
</li>
<li><p>大数据的核心工作：数据存储，数据计算，数据传输</p>
<ul>
<li><p>数据存储：</p>
<p>HDFS</p>
<p>HBase是大数据体系内使用非常广泛的NoSQL KV型数据库技术HBase是基于HDFS之上构建的。</p>
</li>
<li><p>数据计算：</p>
<p>MapReduce：组件是最早一代的大数据分布式计算引擎对大数据的发展做出了卓越的贡献</p>
<p> Hive：是一款以SQL为要开发语言的分布式计算框架。</p>
<p>Spark：是目前全球范围内最火热的分布式内存计算引擎。是大数据体系中的明星计算产品</p>
<p>Flink：同样也是一款明星级的大数据分布式内存计算引擎。</p>
</li>
<li><p>数据传输：</p>
<p>Flume：是一款流式数据采集工具，可以从非常多的数据源中完成数据采集传输的任务。</p>
<p> Sqoop：是一款ETL工具，可以协助大数据体系和关系型数据库之间进行数据传输。</p>
<p>Kafka：是一款分布式的消息系统，可以完成海量规模的数据传输工作。</p>
<p>Pulsar：同样是一款分布式的消息系统。</p>
</li>
</ul>
</li>
<li><p>大数据软件生态</p>
<ul>
<li>存储：Apache Hadoop HDFS、Apache HBase、Apache Kudu、云平台</li>
<li>计算：Apache Hadoop MapReduce、Apache Spark、Apache Flink</li>
<li>传输：Apache Kafka、Apache Pulsar、Apache Flume、Apache Sqoop</li>
</ul>
</li>
<li><p>商业发行版本：CDH，HDP，星环</p>
</li>
</ol>
<h1 id="第三章-HDFS分布式文件系统"><a href="#第三章-HDFS分布式文件系统" class="headerlink" title="第三章 HDFS分布式文件系统"></a>第三章 HDFS分布式文件系统</h1><p>Hadoop三大组件（HDFS，MapReduce，YARN）</p>
<h2 id="HDFS的基本概念"><a href="#HDFS的基本概念" class="headerlink" title="HDFS的基本概念"></a>HDFS的基本概念</h2><ol>
<li>NameNode（名称节点&#x2F;主节点）：是HDFS集群的主服务器</li>
<li>DataNode（数据节点）：是HDFS集群的从服务器</li>
<li>Secondary NameNode（辅助名称节点）：通过http从NameNode拉取数据（edits和fsimage）然后合并完成后提供给NameNode使用</li>
<li>Block（数据块）</li>
<li>Rack（机架）</li>
<li>Metadata（元数据）：<ul>
<li>维护HDFS中文件和目录的信息</li>
<li>记录文件内容，存储相关信息</li>
<li>用来记录HDFS中所有DataNode的信息</li>
</ul>
</li>
</ol>
<h2 id="HDFS的特点"><a href="#HDFS的特点" class="headerlink" title="HDFS的特点"></a>HDFS的特点</h2><ol>
<li>优点<ul>
<li>高容错</li>
<li>流式数据访问</li>
<li>支持超大文件</li>
<li>高数据吞吐量：一旦写入就不能进行修改了，只能追加或者删除。</li>
<li>可构建在廉价的机器上</li>
</ul>
</li>
<li>缺点<ul>
<li>高延迟</li>
<li>不适合小文件存取场景</li>
<li>不适合并发写入：不支持并发多用户的写操作</li>
</ul>
</li>
</ol>
<h2 id="HDFS存储架构"><a href="#HDFS存储架构" class="headerlink" title="HDFS存储架构"></a>HDFS存储架构</h2><ol>
<li><p>大数据体系中，分布式的调度主要有2类架构模式：</p>
<ul>
<li>去中心化模式</li>
<li>中心化模式（主从架构&#x2F;主从模式）：就是中心化模式，表示有一个主节点来作为管理者，管理协调下属一批从节点工作。</li>
</ul>
</li>
<li><p>NameNode：：存储的是元数据信息。</p>
<p>DataNode：存储真正的数据信息</p>
<p>SecondaryNameNode：主要帮助NameNode完成元数据整理工作。</p>
</li>
<li><p>HDFS文件的读写原理（略）</p>
</li>
</ol>
<h2 id="HDFS的Shell操作"><a href="#HDFS的Shell操作" class="headerlink" title="HDFS的Shell操作"></a>HDFS的Shell操作</h2><h3 id="一键启停脚本"><a href="#一键启停脚本" class="headerlink" title="一键启停脚本"></a>一键启停脚本</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br><span class="line">stop-dfs.sh</span><br></pre></td></tr></table></figure>



<h3 id="HDFS文件系统基本信息"><a href="#HDFS文件系统基本信息" class="headerlink" title="HDFS文件系统基本信息"></a>HDFS文件系统基本信息</h3><p>HDFS同Linux系统一样，均是以 &#x2F; 作为根目录的组织形式</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs 新版命令，只是前缀不同</span><br><span class="line"></span><br><span class="line">1.创建文件夹</span><br><span class="line">hadoop fs -mkdir [-p] &lt;path&gt; ...</span><br><span class="line">    path 为待创建的目录</span><br><span class="line">    -p选项的行为与Linux mkdir -p一致，它会沿着路径创建父目录。</span><br><span class="line"></span><br><span class="line">2.查看目录内容</span><br><span class="line">hadoop fs -ls [-h] [-R] [&lt;path&gt; ...] </span><br><span class="line">	path 指定目录路径</span><br><span class="line">	-h 人性化显示文件size</span><br><span class="line">	-R 递归查看指定目录及其子目录</span><br><span class="line"></span><br><span class="line">3.上传文件到HDFS指定目录下</span><br><span class="line">hadoop fs -put [-f] [-p] &lt;localsrc&gt; ... &lt;dst&gt;</span><br><span class="line">	-f 覆盖目标文件（已存在下）</span><br><span class="line">	-p 保留访问和修改时间，所有权和权限。</span><br><span class="line">	localsrc 本地文件系统（客户端所在机器）</span><br><span class="line">	dst 目标文件系统（HDFS）</span><br><span class="line"></span><br><span class="line">4.查看HDFS文件内容</span><br><span class="line">hadoop fs -cat &lt;src&gt; ... </span><br><span class="line">    读取指定文件全部内容，显示在标准输出控制台</span><br><span class="line">    </span><br><span class="line">    读取大文件可以使用管道符配合more</span><br><span class="line">        hadoop fs -cat &lt;src&gt; | more</span><br><span class="line">        hdfs dfs -cat &lt;src&gt; | more</span><br><span class="line"></span><br><span class="line">5.下载HDFS文件</span><br><span class="line">hadoop fs -get [-f] [-p] &lt;src&gt; ... &lt;localdst&gt;</span><br><span class="line">    下载文件到本地文件系统指定目录，localdst必须是目录</span><br><span class="line">    -f 覆盖目标文件（已存在下）</span><br><span class="line">    -p 保留访问和修改时间，所有权和权限。</span><br><span class="line"></span><br><span class="line">6.拷贝HDFS文件</span><br><span class="line">hadoop fs -cp [-f] &lt;src&gt; ... &lt;dst&gt; </span><br><span class="line">    -f 覆盖目标文件（已存在下）</span><br><span class="line"></span><br><span class="line">7.追加数据到HDFS文件中</span><br><span class="line">hadoop fs -appendToFile &lt;localsrc&gt; ... &lt;dst&gt;</span><br><span class="line">    将所有给定本地文件的内容追加到给定dst文件。 </span><br><span class="line">    dst如果文件不存在，将创建该文件。 </span><br><span class="line">    如果&lt;localSrc&gt;为-，则输入为从标准输入中读取。</span><br><span class="line"></span><br><span class="line">8.HDFS数据移动操作</span><br><span class="line">hadoop fs -mv &lt;src&gt; ... &lt;dst&gt;	</span><br><span class="line">    移动文件到指定文件夹下</span><br><span class="line">    可以使用该命令移动数据，重命名文件的名称</span><br><span class="line"></span><br><span class="line">9.HDFS数据删除操作</span><br><span class="line">hadoop fs -rm -r [-skipTrash] URI </span><br><span class="line">	[URI ...] 删除指定路径的文件或文件夹</span><br><span class="line">    -skipTrash 跳过回收站，直接删除（默认回收站是关闭状态）</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>HDFS shell其它命令：<a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r3.3.4/hadoop-project-dist/hadoop-common/FileSystemShell.html">官方命令指导文档</a></p>
<h2 id="HDFS分布式文件存储"><a href="#HDFS分布式文件存储" class="headerlink" title="HDFS分布式文件存储"></a>HDFS分布式文件存储</h2><ol>
<li><p>问题：文件大小不一，不利于统一管理</p>
<p>解决：设定统一的管理单位，block块</p>
</li>
<li><p>NameNode基于一批edits和一个fsimage文件的配合完成整个文件系统的管理和维护</p>
<ul>
<li>edits文件：是一个流水账文件，记录了hdfs中的每一次操作，以及本次操作影响的文件其对应的block</li>
<li>FSImage文件：将全部的edits文件，合并为最终结果</li>
</ul>
</li>
</ol>
<h1 id="第四章-MapReduce分布式计算框架"><a href="#第四章-MapReduce分布式计算框架" class="headerlink" title="第四章 MapReduce分布式计算框架"></a>第四章 MapReduce分布式计算框架</h1><h2 id="MapReduce概述"><a href="#MapReduce概述" class="headerlink" title="MapReduce概述"></a>MapReduce概述</h2><ol>
<li>MapReduce核心思想是：分而治之</li>
<li>MapReduce作为一种分布式计算模型，它主要用于解决海量数据的计算问题。<ul>
<li>Map阶段：负责将任务分解，并行处理</li>
<li>Reduce阶段：负责将任务合并，即把Map阶段的结果进行全局汇总</li>
</ul>
</li>
<li>从数据格式上看map（）函数接受键值对数据，输出键值对数据。reduce（）函数将map（）输出的键值对作为输入，把相同的key的value进行汇总输出新的键值对。</li>
</ol>
<h2 id="MapReduce工作原理"><a href="#MapReduce工作原理" class="headerlink" title="MapReduce工作原理"></a>MapReduce工作原理</h2><p>（见课本：P73页- P100）</p>
<h1 id="第五章-Zookeeper分布式协调服务"><a href="#第五章-Zookeeper分布式协调服务" class="headerlink" title="第五章 Zookeeper分布式协调服务"></a>第五章 Zookeeper分布式协调服务</h1><p>推荐视频：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1M741137qY?p=74">黑马程序员</a></p>
<h2 id="初识Zookeeper"><a href="#初识Zookeeper" class="headerlink" title="初识Zookeeper"></a>初识Zookeeper</h2><ol>
<li><p>Zookeeper简介</p>
<ul>
<li>Zookeeper是进行分布式服务的协调</li>
<li>本质上是一个分布式的小文件存储系统</li>
</ul>
</li>
<li><p>Zookeeper的特性：其他特性都是为了满足Zookeeper全局数据一致性</p>
<ul>
<li>全局数据一致性：每个服务器都保存一份相同的数据副本，客户端连接到集群的任意节点上，看到的数据都是一致的。</li>
<li>可靠性</li>
<li>顺序性</li>
<li>数据更新原子性</li>
<li>实时性</li>
</ul>
</li>
<li><p>Zookeeper集群的角色</p>
<p>每一个Zookeeper都是由多台服务器节点组成，这些节点通过复制保证各个服务器节点之间的数据一致。<strong>只要这些服务器节点过半数可用，那么整个Zookeeper集群就可用。</strong></p>
<ol>
<li>leader：Zookeeper集群工作的核心，也是事务性请求的唯一调度者和处理者。</li>
<li>follower：负责处理客户端的非事务请求。</li>
<li>observer：负责观察Zookeeper集群的最新状态变化，并将这些状态进行同步。</li>
</ol>
</li>
</ol>
<h2 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h2><ol>
<li>数据采用树状层次结构</li>
<li>Znode的类型：<ul>
<li>临时节点：生命周期依赖于创建它们的会话</li>
<li>永久节点：生命周期<strong>不</strong>依赖于创建它们的会话</li>
</ul>
</li>
<li>Znode的属性：其中重要的概念是<code>Zxid(Zookeeper Transaction ID)</code>，<code>Zookeeper</code>结点的每一次更改都具有唯一的<code>Zxid</code>，如果<code>Zxid-1</code> 小于<code> Zxid-2</code> ，则<code>Zxid-1</code> 的更改发生在 <code>Zxid-2 </code>更改之前<ul>
<li><code>czxid</code>：数据结点创建时的事务ID——针对于<code>zookeeper</code>数据结点的管理：我们对结点数据的一些写操作都会导致<code>zookeeper</code>自动地为我们去开启一个事务，并且自动地去为每一个事务维护一个事务<code>ID</code></li>
<li><code>ctime</code>数据结点创建时的时间</li>
<li><code>mZxid</code>数据结点最后一次更新时的事务ID</li>
<li><code>mtime</code>数据结点最后一次更新时的时间</li>
<li><code>pZxid</code>数据节点最后一次修改此<code>znode</code>子节点更改的<code>zxid</code></li>
<li><code>cversion</code>子结点的更改次数</li>
<li><code>dataVersion</code>结点数据的更改次数</li>
<li><code>aclVersion</code>结点的ACL更改次数——类似<code>linux</code>的权限列表，维护的是当前结点的权限列表被修改的次数</li>
<li><code>ephemeralOwner</code>如果结点是临时结点，则表示创建该结点的会话的<code>SessionID</code>；如果是持久结点，该属性值为0</li>
<li><code>dataLength</code>数据内容的长度</li>
<li><code>numChildren</code>数据结点当前的子结点个数</li>
</ul>
</li>
</ol>
<h2 id="Zookeeper的Watch机制"><a href="#Zookeeper的Watch机制" class="headerlink" title="Zookeeper的Watch机制"></a>Zookeeper的Watch机制</h2><p>Watch机制：实现分布式的通知功能。</p>
<ol>
<li>Watch机制的特点<ul>
<li>一次性触发：后续发生同样的事件，也不会再次触发。</li>
<li>事件封装：</li>
<li>异步发送</li>
<li>先注册，再触发</li>
</ul>
</li>
<li>Watch机制的通知状态和事件类型（107）</li>
</ol>
<h2 id="Zookeeper的选举机制"><a href="#Zookeeper的选举机制" class="headerlink" title="Zookeeper的选举机制"></a>Zookeeper的选举机制</h2><ol>
<li>选举机制：<ul>
<li>服务器ID：设置myid参数文件，编号越大，在算法中的权重越大</li>
<li>选举状态：4种。竞选，随从，观察，领导者。</li>
<li>数据ID：选举过程中，数据越新，权重越大</li>
<li>逻辑时钟：投票次数。</li>
</ul>
</li>
<li>选举机制的类型<ul>
<li>全新集群选举</li>
<li>非全新集群选举</li>
</ul>
</li>
</ol>
<h2 id="Zookeeper的集群部署"><a href="#Zookeeper的集群部署" class="headerlink" title="Zookeeper的集群部署"></a>Zookeeper的集群部署</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">1.上传文件到：/export/softwere</span><br><span class="line"></span><br><span class="line">2.</span><br><span class="line">cd /export/software/</span><br><span class="line"></span><br><span class="line">3.</span><br><span class="line">tar -zxvf apache-zookeeper-3.7.0-bin.tar.gz -C /export/servers/</span><br><span class="line"></span><br><span class="line">4.</span><br><span class="line">cd ../servers/</span><br><span class="line">mv apache-zookeeper-3.7.0-bin/ zookeeper-3.7.0</span><br><span class="line"></span><br><span class="line">5.</span><br><span class="line">cd zookeeper-3.7.0/conf/</span><br><span class="line">cp zoo_sample.cfg zoo.cfg</span><br><span class="line">vim zoo.cfg </span><br><span class="line">找到并修改：dataDir=/export/data/zookeeper/zkdata</span><br><span class="line">最下方输入：</span><br><span class="line">server.1=hadoop01:2888:3888</span><br><span class="line">server.2=hadoop02:2898:3898</span><br><span class="line">server.3=hadoop03:2889:3889</span><br><span class="line"></span><br><span class="line">6.</span><br><span class="line">mkdir -p /export/data/zookeeper/zkdata</span><br><span class="line">cd /export/data/zookeeper/zkdata</span><br><span class="line">echo 1 &gt;myid</span><br><span class="line"></span><br><span class="line">7.</span><br><span class="line">vim /etc/profile</span><br><span class="line">最下面输入：</span><br><span class="line">export ZK_HOME=/export/servers/zookeeper-3.7.0</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$ZK_HOME/bin</span><br><span class="line">保存退出</span><br><span class="line"></span><br><span class="line">8.</span><br><span class="line">scp -r /export/servers/zookeeper-3.7.0/ hadoop02:/export/servers/</span><br><span class="line">scp -r /export/servers/zookeeper-3.7.0/ hadoop03:/export/servers/</span><br><span class="line"></span><br><span class="line">scp -r /export/data/zookeeper/ hadoop02:/export/data/</span><br><span class="line">scp -r /export/data/zookeeper/ hadoop03:/export/data/</span><br><span class="line"></span><br><span class="line">scp /etc/profile hadoop02:/etc/profile</span><br><span class="line">scp /etc/profile hadoop03:/etc/profile</span><br><span class="line"></span><br><span class="line">3个输入：</span><br><span class="line">source /etc/profile</span><br><span class="line"></span><br><span class="line">在Hadoop02输入：</span><br><span class="line">cd /export/data/zookeeper/zkdata/</span><br><span class="line">echo 2 &gt;myid</span><br><span class="line"></span><br><span class="line">在Hadoop03输入：</span><br><span class="line">cd /export/data/zookeeper/zkdata/</span><br><span class="line">echo 3 &gt;myid</span><br><span class="line"></span><br><span class="line">9.</span><br><span class="line">启动服务，3个依次输入：</span><br><span class="line">zkServer.sh start</span><br><span class="line"></span><br><span class="line">查看角色：</span><br><span class="line">zkServer.sh status</span><br><span class="line">	注意：在输入这个命令的时候报错，无法查看mode的话，极大的可能性是没有关闭防火墙（究极折磨，我配置了10多次才找到问题，问老师真问题的边都没找到）</span><br><span class="line">	如果出错输入：</span><br><span class="line">	systemctl stop firewalld  #停止firewall防火墙</span><br><span class="line">	systemctl disable firewalld  #禁止firewall开机启动</span><br><span class="line">	（详细解决方案；https://blog.csdn.net/white_mvlog/article/details/112878757）</span><br><span class="line"></span><br><span class="line">关闭服务：</span><br><span class="line">zkServer.sh stop</span><br></pre></td></tr></table></figure>







<h2 id="Zookeeper的shell操作"><a href="#Zookeeper的shell操作" class="headerlink" title="Zookeeper的shell操作"></a>Zookeeper的shell操作</h2><table>
<thead>
<tr>
<th align="center">常用命令</th>
<th align="center">命令描述</th>
</tr>
</thead>
<tbody><tr>
<td align="center">ls &#x2F;</td>
<td align="center">查看Zookeeper中所包含的内容</td>
</tr>
<tr>
<td align="center">ls2 &#x2F;</td>
<td align="center">查看当前节点数据，并能看见更新次数等数据</td>
</tr>
<tr>
<td align="center">create &#x2F;zk “test”</td>
<td align="center">创建一个新的节点zk以及与他关联的字符串</td>
</tr>
<tr>
<td align="center">get &#x2F;zk</td>
<td align="center">获取zk所包含的信息</td>
</tr>
<tr>
<td align="center">set &#x2F;zk “zkbak”</td>
<td align="center">对zk所关联的字符串进行设置</td>
</tr>
<tr>
<td align="center">delete &#x2F;zk</td>
<td align="center">删除节点</td>
</tr>
<tr>
<td align="center">rmr</td>
<td align="center">递归删除节点</td>
</tr>
<tr>
<td align="center">help</td>
<td align="center">帮助命令</td>
</tr>
</tbody></table>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">1.启动服务：</span><br><span class="line">zkServer.sh start</span><br><span class="line"></span><br><span class="line">2.连接zookeeoper服务：</span><br><span class="line">zkCli.sh -server localhost:2181</span><br><span class="line"></span><br><span class="line">3.</span><br><span class="line">ls /</span><br><span class="line"></span><br><span class="line">4.</span><br><span class="line">ls2 /</span><br><span class="line"></span><br><span class="line">5.create [-s] [-e] path data acl</span><br><span class="line">	-s:是否开启节点的序列化特性</span><br><span class="line">	-e:开启临时节点特性，不指定则是永久节点</span><br><span class="line">	path：创建的路径</span><br><span class="line">	data：创建节点的数据</span><br><span class="line">	acl:权限控制，，一般了解</span><br><span class="line"></span><br><span class="line">6.监听节点</span><br><span class="line">get /testnode-tem watch</span><br><span class="line">set /testnode-tem testwatch</span><br></pre></td></tr></table></figure>



<h1 id="第六章-YARN资源管理框架"><a href="#第六章-YARN资源管理框架" class="headerlink" title="第六章 YARN资源管理框架"></a>第六章 YARN资源管理框架</h1><h2 id="YARN体系结构"><a href="#YARN体系结构" class="headerlink" title="YARN体系结构"></a>YARN体系结构</h2><p>YARN：是一个通用的资源管理系统和调度平台</p>
<p>YARN的三大核心组件：</p>
<ol>
<li>ResourceManager：是一个全局的资源管理系统，负责整个YARN集群资源的监控、分配和管理工作。<ul>
<li>负责处理客户端请求</li>
<li>接收和监控NodeManager的资源情况</li>
<li>启动和监控ApplicationMaster</li>
<li>资源的分配和调度</li>
</ul>
</li>
<li>NodeManager：是每个节点上的资源和任务管理器。</li>
<li>ApplicationMaster：</li>
</ol>
<h1 id="第七章-Hive数据仓库"><a href="#第七章-Hive数据仓库" class="headerlink" title="第七章 Hive数据仓库"></a>第七章 Hive数据仓库</h1><h2 id="数据仓库简介"><a href="#数据仓库简介" class="headerlink" title="数据仓库简介"></a>数据仓库简介</h2><ol>
<li><p>数据仓库是一个面向主题的，集成的，随时间变化的，但信息本身相对稳定的数据集合。</p>
<p>数据处理大致分为2类：</p>
<ul>
<li>联机事务处理（OLTP）：传统关系数据库的主要应用</li>
<li>联机分析处理（OLAP）：数据仓库的主要应用</li>
</ul>
</li>
<li><p>数据仓库的结构：数据源，数据存储及管理，OLAP服务器，前端工具。</p>
</li>
<li><p>数据仓库的数据模型</p>
<ul>
<li>星型模型</li>
<li>雪花模型：星型模型的扩展</li>
</ul>
</li>
<li><p>事务表，维度表</p>
</li>
</ol>
<h2 id="Hive简介"><a href="#Hive简介" class="headerlink" title="Hive简介"></a>Hive简介</h2><ol>
<li><p>Hive是建立再Hadoop文件系统上的数据仓库，是一种可以存储，查询和分析存储在Hadoop中的大规模数据的工具。</p>
</li>
<li><p>Hive使用的是HQL查询语言</p>
<table>
<thead>
<tr>
<th>对比项</th>
<th>Hive</th>
<th>MySQL</th>
</tr>
</thead>
<tbody><tr>
<td>查询语言</td>
<td>HQL</td>
<td>SQL</td>
</tr>
<tr>
<td>数据更新</td>
<td>不支持</td>
<td>支持</td>
</tr>
<tr>
<td>事务</td>
<td>不支持</td>
<td>支持</td>
</tr>
<tr>
<td>多表插入</td>
<td>支持</td>
<td>不支持</td>
</tr>
</tbody></table>
</li>
<li><p>Hive系统架构</p>
<ul>
<li>用户接口：CLI，JDBC&#x2F;ODBC，webUI。CLI为Shell终端命令行。</li>
<li>跨语言服务</li>
<li>底层的驱动引擎：编译器，优化器，执行器。</li>
<li>元数据存储系统</li>
</ul>
</li>
<li><p>Hive数据模型：Hive中所有的数据都存储在HDFS中。包含：</p>
<ul>
<li>数据库</li>
<li>表</li>
<li>分区</li>
<li>桶表</li>
</ul>
</li>
</ol>
<h2 id="Hive的安装"><a href="#Hive的安装" class="headerlink" title="Hive的安装"></a>Hive的安装</h2><p>安装分为3种模式：嵌入模式，本地模式，远程模式。</p>
<p><strong>注：</strong>要先启动HDFS服务：start-dfs.sh</p>
<ol>
<li><p>嵌入模式（可忽略，只测试使用）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">嵌入模式：使用的内嵌Derby数据库存储元数据。一次只能连接一个客户端。</span><br><span class="line"></span><br><span class="line">1.上传文件到/export/software</span><br><span class="line"></span><br><span class="line">2.解压</span><br><span class="line">tar -zxvf apache-hive-3.1.2-bin.tar.gz -C /export/servers/</span><br><span class="line"></span><br><span class="line">3.</span><br><span class="line">cd /export/servers/</span><br><span class="line">mv apache-hive-3.1.2-bin/ hive-3.1.2</span><br><span class="line">cd hive-3.1.2</span><br><span class="line"></span><br><span class="line">4.启动Hive程序</span><br><span class="line">bin/hive</span><br></pre></td></tr></table></figure>


</li>
<li><p>本地模式，远程模式</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">本地模式，远程模式</span><br><span class="line">1.安装MySQL服务</span><br><span class="line">yum install mysql mysql-server mysql-devel</span><br><span class="line">systemctl start mysqld</span><br><span class="line">mysql</span><br><span class="line">use mysql;</span><br><span class="line">update user set host=&quot;%&quot;;</span><br><span class="line">alter user &#x27;root&#x27;@&#x27;%&#x27; identified with mysql_native_password by &quot;root&quot;;</span><br><span class="line">flush privileges;</span><br><span class="line"></span><br><span class="line">2.在/export/software下，解压</span><br><span class="line">tar -zxvf apache-hive-3.1.2-bin.tar.gz -C /export/servers/</span><br><span class="line"></span><br><span class="line">3.复制MySQL安装包(JDBC的jar包)</span><br><span class="line">cp mysql-connector-java-8.0.17.jar /export/servers/apache-hive-3.1.2-bin/lib/</span><br><span class="line"></span><br><span class="line">4.重命名</span><br><span class="line">cd /export/servers/</span><br><span class="line">mv apache-hive-3.1.2-bin/ hive-3.1.2</span><br><span class="line"></span><br><span class="line">5.Hive的配置</span><br><span class="line">（1）</span><br><span class="line">cd hive-3.1.2/conf/</span><br><span class="line">cp hive-env.sh.template hive-env.sh</span><br><span class="line">vim hive-env.sh</span><br><span class="line">添加</span><br><span class="line">export HADOOP_HOME=/export/servers/hadoop-2.10.0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">（2）vim hive-site.xml</span><br><span class="line">输入：</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">		&lt;value&gt; jdbc:mysql://hadoop01:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt;</span><br><span class="line">		&lt;description&gt;Mysql 连接协议&lt;/description&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;com.mysql.cj.jdbc.Driver&lt;/value&gt;</span><br><span class="line">        &lt;dеѕсrірtіоn&gt;JDВС连接驱动&lt;/dеѕсrірtіоn&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">        &lt;description&gt;用户名&lt;/description&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">    	&lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">    	&lt;value&gt;root&lt;/value&gt;</span><br><span class="line">    	&lt;description&gt;密码&lt;/description&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">6.初始化，在hive-3.1.2/bin目录下：</span><br><span class="line">./schematool -dbType mysql -initSchemayu</span><br></pre></td></tr></table></figure>
</li>
<li><p>远程服务</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">1.复制hive:</span><br><span class="line">scp -r /scp -r /export/servers/hive-3.1.2/ hadoop02:/export/servers/</span><br><span class="line">scp -r /export/servers/hive-3.1.2/ hadoop03:/export/servers/</span><br><span class="line"></span><br><span class="line">2.在Hive目录下，启动服务（注意启动dfs,yarn服务）：</span><br><span class="line">bin/hiveserver2</span><br><span class="line">(输入完成后，命令行将无法进行其他操作)</span><br><span class="line"></span><br><span class="line">3.进入Hadoop02，输入:</span><br><span class="line">ssh hadoop01</span><br><span class="line">cd /export/servers/hive-3.1.2/</span><br><span class="line">bin/beeline</span><br><span class="line">! connect jdbc:hive2://hadoop01:10000</span><br><span class="line">	如果出错：</span><br><span class="line">	cd /export/servers/hadoop-2.10.0/etc/hadoop/</span><br><span class="line">	vim core-site.xml </span><br><span class="line">	添加：</span><br><span class="line">        &lt;!--置超级代理--&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">          &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt;</span><br><span class="line">          &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">          &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt;</span><br><span class="line">          &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></div><div class="post_share"><div class="social-share" data-image="/img/%E5%9B%BE%E7%89%87/015.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/11/04/4.%E8%AE%A1%E7%AE%97%E6%9C%BA/1.%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/1.Crash%20Course%20Computer%20Science%EF%BC%88%E6%9C%AA%E5%AE%8C%E7%BB%93%EF%BC%89/" title="Crash Course Computer Science"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/%E5%9B%BE%E7%89%87/012.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Crash Course Computer Science</div></div></a></div><div class="next-post pull-right"><a href="/2024/01/01/5.DIY/1.%E7%BD%91%E9%A1%B5%E6%90%AD%E5%BB%BA/1.%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/" title="零成本博客搭建"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/%E5%9B%BE%E7%89%87/011.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">零成本博客搭建</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/touxiang.JPG" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">HQH</div><div class="author-info__description">我要睡到自然醒</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">12</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/silent-wuhen"><i class="fab fa-github"></i><span>GitHub</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">此网站仅个人学习使用，如有侵权请联系QQ：3281320387删除。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E7%AB%A0-%E6%90%AD%E5%BB%BAHadoop%E9%9B%86%E7%BE%A4"><span class="toc-number">2.</span> <span class="toc-text">第一章 搭建Hadoop集群</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%90%AD%E5%BB%BA%E5%87%86%E5%A4%87"><span class="toc-number">2.1.</span> <span class="toc-text">搭建准备</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E5%BC%8F%E6%90%AD%E5%BB%BA"><span class="toc-number">2.2.</span> <span class="toc-text">正式搭建</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop%E9%9B%86%E7%BE%A4%E6%B5%8B%E8%AF%95"><span class="toc-number">2.3.</span> <span class="toc-text">Hadoop集群测试</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop%E9%9B%86%E7%BE%A4%E5%88%9D%E4%BD%93%E9%AA%8C"><span class="toc-number">2.4.</span> <span class="toc-text">Hadoop集群初体验</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E5%88%9D%E8%AF%86Hadoop"><span class="toc-number">3.</span> <span class="toc-text">第二章 初识Hadoop</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E7%AB%A0-HDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F"><span class="toc-number">4.</span> <span class="toc-text">第三章 HDFS分布式文件系统</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">4.1.</span> <span class="toc-text">HDFS的基本概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E7%9A%84%E7%89%B9%E7%82%B9"><span class="toc-number">4.2.</span> <span class="toc-text">HDFS的特点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E5%AD%98%E5%82%A8%E6%9E%B6%E6%9E%84"><span class="toc-number">4.3.</span> <span class="toc-text">HDFS存储架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E7%9A%84Shell%E6%93%8D%E4%BD%9C"><span class="toc-number">4.4.</span> <span class="toc-text">HDFS的Shell操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E9%94%AE%E5%90%AF%E5%81%9C%E8%84%9A%E6%9C%AC"><span class="toc-number">4.4.1.</span> <span class="toc-text">一键启停脚本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%9F%BA%E6%9C%AC%E4%BF%A1%E6%81%AF"><span class="toc-number">4.4.2.</span> <span class="toc-text">HDFS文件系统基本信息</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8"><span class="toc-number">4.5.</span> <span class="toc-text">HDFS分布式文件存储</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E7%AB%A0-MapReduce%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6"><span class="toc-number">5.</span> <span class="toc-text">第四章 MapReduce分布式计算框架</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce%E6%A6%82%E8%BF%B0"><span class="toc-number">5.1.</span> <span class="toc-text">MapReduce概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-number">5.2.</span> <span class="toc-text">MapReduce工作原理</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%94%E7%AB%A0-Zookeeper%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E6%9C%8D%E5%8A%A1"><span class="toc-number">6.</span> <span class="toc-text">第五章 Zookeeper分布式协调服务</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9D%E8%AF%86Zookeeper"><span class="toc-number">6.1.</span> <span class="toc-text">初识Zookeeper</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.2.</span> <span class="toc-text">数据模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Zookeeper%E7%9A%84Watch%E6%9C%BA%E5%88%B6"><span class="toc-number">6.3.</span> <span class="toc-text">Zookeeper的Watch机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Zookeeper%E7%9A%84%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6"><span class="toc-number">6.4.</span> <span class="toc-text">Zookeeper的选举机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Zookeeper%E7%9A%84%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2"><span class="toc-number">6.5.</span> <span class="toc-text">Zookeeper的集群部署</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Zookeeper%E7%9A%84shell%E6%93%8D%E4%BD%9C"><span class="toc-number">6.6.</span> <span class="toc-text">Zookeeper的shell操作</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%85%AD%E7%AB%A0-YARN%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E6%A1%86%E6%9E%B6"><span class="toc-number">7.</span> <span class="toc-text">第六章 YARN资源管理框架</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#YARN%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84"><span class="toc-number">7.1.</span> <span class="toc-text">YARN体系结构</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%83%E7%AB%A0-Hive%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93"><span class="toc-number">8.</span> <span class="toc-text">第七章 Hive数据仓库</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E7%AE%80%E4%BB%8B"><span class="toc-number">8.1.</span> <span class="toc-text">数据仓库简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive%E7%AE%80%E4%BB%8B"><span class="toc-number">8.2.</span> <span class="toc-text">Hive简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive%E7%9A%84%E5%AE%89%E8%A3%85"><span class="toc-number">8.3.</span> <span class="toc-text">Hive的安装</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/04/28/4.%E8%AE%A1%E7%AE%97%E6%9C%BA/4.Linux/1.Shell%E7%BC%96%E7%A8%8B/" title="Shell编程"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/%E5%9B%BE%E7%89%87/015.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Shell编程"/></a><div class="content"><a class="title" href="/2024/04/28/4.%E8%AE%A1%E7%AE%97%E6%9C%BA/4.Linux/1.Shell%E7%BC%96%E7%A8%8B/" title="Shell编程">Shell编程</a><time datetime="2024-04-28T11:00:12.000Z" title="发表于 2024-04-28 19:00:12">2024-04-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/03/30/6.%E5%85%B6%E4%BB%96%EF%BC%88%E9%9D%9E%E8%AE%A1%E7%AE%97%E6%9C%BA%EF%BC%89/2.English/1.English%20grammar/" title="English grammar"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/%E5%9B%BE%E7%89%87/014.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="English grammar"/></a><div class="content"><a class="title" href="/2024/03/30/6.%E5%85%B6%E4%BB%96%EF%BC%88%E9%9D%9E%E8%AE%A1%E7%AE%97%E6%9C%BA%EF%BC%89/2.English/1.English%20grammar/" title="English grammar">English grammar</a><time datetime="2024-03-30T15:16:12.000Z" title="发表于 2024-03-30 23:16:12">2024-03-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/03/01/2.Java/1.Java%E5%90%8E%E7%AB%AF/1.Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/" title="JavaSE语法"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/%E5%9B%BE%E7%89%87/013.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="JavaSE语法"/></a><div class="content"><a class="title" href="/2024/03/01/2.Java/1.Java%E5%90%8E%E7%AB%AF/1.Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/" title="JavaSE语法">JavaSE语法</a><time datetime="2024-03-01T14:00:00.000Z" title="发表于 2024-03-01 22:00:00">2024-03-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/01/11/6.%E5%85%B6%E4%BB%96%EF%BC%88%E9%9D%9E%E8%AE%A1%E7%AE%97%E6%9C%BA%EF%BC%89/1.%E9%80%BB%E8%BE%91%E6%80%9D%E8%80%83/1.%E5%B9%BB%E6%83%B3%E5%A5%87%E6%9C%AF%E5%B8%88%EF%BC%88%E6%9C%AA%E5%AE%8C%E7%BB%93%EF%BC%89/" title="幻想奇术师"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/%E5%9B%BE%E7%89%87/015.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="幻想奇术师"/></a><div class="content"><a class="title" href="/2024/01/11/6.%E5%85%B6%E4%BB%96%EF%BC%88%E9%9D%9E%E8%AE%A1%E7%AE%97%E6%9C%BA%EF%BC%89/1.%E9%80%BB%E8%BE%91%E6%80%9D%E8%80%83/1.%E5%B9%BB%E6%83%B3%E5%A5%87%E6%9C%AF%E5%B8%88%EF%BC%88%E6%9C%AA%E5%AE%8C%E7%BB%93%EF%BC%89/" title="幻想奇术师">幻想奇术师</a><time datetime="2024-01-11T15:16:12.000Z" title="发表于 2024-01-11 23:16:12">2024-01-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/01/01/5.DIY/1.%E7%BD%91%E9%A1%B5%E6%90%AD%E5%BB%BA/1.%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/" title="零成本博客搭建"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/%E5%9B%BE%E7%89%87/011.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="零成本博客搭建"/></a><div class="content"><a class="title" href="/2024/01/01/5.DIY/1.%E7%BD%91%E9%A1%B5%E6%90%AD%E5%BB%BA/1.%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/" title="零成本博客搭建">零成本博客搭建</a><time datetime="2024-01-01T03:46:12.000Z" title="发表于 2024-01-01 11:46:12">2024-01-01</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2024 By HQH</div><div class="footer_custom_text">Hi,welcome to my blog!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"></div><script defer src="/js/cursor.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="30" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="false" data-text="别卷了,别睡了,干饭了" data-fontsize="15px" data-random="false" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v6.2.0" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" data-title="主题版本Butterfly_v4.3.1" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://vercel.com/" style="margin-inline:5px" data-title="本站采用多线部署，主线路托管于Vercel" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Vercel-brightgreen?style=flat&amp;logo=Vercel" alt=""/></a><a class="github-badge" target="_blank" href="https://dashboard.4everland.org/" style="margin-inline:5px" data-title="本站采用多线部署，备用线路托管于4EVERLAND" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-4EVERLAND-22DDDD?style=flat&amp;logo=IPFS" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="本站项目由Github托管" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></p>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><script async src="/js/runtime.js"></script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '2s');
    arr[i].setAttribute('data-wow-delay', '1s');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><!-- hexo injector body_end end --></body></html>